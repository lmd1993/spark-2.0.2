package org.apache.spark.sql.catalyst.optimizer;
public  class ColumnPruningSuite extends org.apache.spark.sql.catalyst.plans.PlanTest {
  public   ColumnPruningSuite ()  { throw new RuntimeException(); }
  public  class Optimize extends org.apache.spark.sql.catalyst.rules.RuleExecutor<org.apache.spark.sql.catalyst.plans.logical.LogicalPlan> {
    public   Optimize ()  { throw new RuntimeException(); }
    public  scala.collection.immutable.List<org.apache.spark.sql.catalyst.rules.RuleExecutor<org.apache.spark.sql.catalyst.plans.logical.LogicalPlan>.Batch> batches ()  { throw new RuntimeException(); }
  }
  public  org.apache.spark.sql.catalyst.optimizer.ColumnPruningSuite.Optimize$ Optimize ()  { throw new RuntimeException(); }
  private <T extends scala.Product> org.apache.spark.sql.catalyst.encoders.ExpressionEncoder<T> productEncoder (scala.reflect.api.TypeTags.TypeTag<T> evidence$1)  { throw new RuntimeException(); }
  private  scala.Function1<scala.collection.Iterator<org.apache.spark.sql.catalyst.optimizer.OtherTuple>, scala.collection.Iterator<org.apache.spark.sql.catalyst.optimizer.OtherTuple>> func ()  { throw new RuntimeException(); }
}
