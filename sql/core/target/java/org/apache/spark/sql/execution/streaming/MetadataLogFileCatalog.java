package org.apache.spark.sql.execution.streaming;
/**
 * A {@link FileCatalog} that generates the list of files to processing by reading them from the
 * metadata log files generated by the {@link FileStreamSink}.
 */
public  class MetadataLogFileCatalog extends org.apache.spark.sql.execution.datasources.PartitioningAwareFileCatalog {
  public   MetadataLogFileCatalog (org.apache.spark.sql.SparkSession sparkSession, org.apache.hadoop.fs.Path path)  { throw new RuntimeException(); }
  private  org.apache.hadoop.fs.Path metadataDirectory ()  { throw new RuntimeException(); }
  private  org.apache.spark.sql.execution.streaming.FileStreamSinkLog metadataLog ()  { throw new RuntimeException(); }
  private  org.apache.hadoop.fs.FileStatus[] allFilesFromLog ()  { throw new RuntimeException(); }
  private  org.apache.spark.sql.execution.datasources.PartitionSpec cachedPartitionSpec ()  { throw new RuntimeException(); }
  protected  scala.collection.mutable.LinkedHashMap<org.apache.hadoop.fs.Path, org.apache.hadoop.fs.FileStatus> leafFiles ()  { throw new RuntimeException(); }
  protected  scala.collection.immutable.Map<org.apache.hadoop.fs.Path, org.apache.hadoop.fs.FileStatus[]> leafDirToChildrenFiles ()  { throw new RuntimeException(); }
  public  scala.collection.Seq<org.apache.hadoop.fs.Path> paths ()  { throw new RuntimeException(); }
  public  void refresh ()  { throw new RuntimeException(); }
  public  org.apache.spark.sql.execution.datasources.PartitionSpec partitionSpec ()  { throw new RuntimeException(); }
}
